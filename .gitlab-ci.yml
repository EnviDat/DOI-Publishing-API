stages:
  - build
  - scan
  - package
  - deploy
  - manual-deploy

variables:
  ARTIFACT_COMPRESSION_LEVEL: "fast"
  CACHE_COMPRESSION_LEVEL: "fast"

.triggers:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: never
    - if: $CI_COMMIT_REF_NAME == "main"
      when: always
    - if: $CI_COMMIT_REF_NAME == "staging"
      when: always
    - if: '$CI_PIPELINE_SOURCE == "web"'
      when: always

set-vars:
  stage: .pre
  image: docker.io/alpine:3.20
  script:
    - echo "DATACITE_DATA_URL_PREFIX=$DATACITE_DATA_URL_PREFIX" >> build.env
    - echo "DOI_PREFIX=$DOI_PREFIX" >> build.env
    - echo "DATACITE_API_URL=$DATACITE_API_URL" >> build.env
    - echo "DOI_SUFFIX_TAG=$DOI_SUFFIX_TAG" >> build.env
    - echo "INTERNAL_REG=$INTERNAL_REG"
    - echo "APP_NAME=$CI_PROJECT_NAME-$CI_COMMIT_REF_NAME" >> build.env
    - "echo APP_IMAGE=$INTERNAL_REG/$CI_PROJECT_NAME:\
      $APP_VERSION-$CI_COMMIT_REF_NAME >> build.env"
    - "echo PROXY_IMAGE=$INTERNAL_REG/$CI_PROJECT_NAME/proxy:\
      $NGINX_IMG_TAG-$CI_COMMIT_REF_NAME >> build.env"
    - cat build.env
  artifacts:
    reports:
      dotenv: build.env

.build:
  stage: build
  image:
    name: gcr.io/kaniko-project/executor:v1.9.1-debug
    entrypoint: [""]
  before_script:
    - mkdir -p /kaniko/.docker
    - echo "going to create kaniko config.json for auth for ${INTERNAL_REG} -> '${IMAGE_REGISTRY_USER}' and https://index.docker.io/v1/ -> '${DOCKER_USERNAME}'"
    - >
      echo "{\"auths\":{
      \"${INTERNAL_REG}\":{
        \"auth\":\"$(printf "%s:%s" "${IMAGE_REGISTRY_USER}" "${IMAGE_REGISTRY_PASS}" | base64 | tr -d '\n')\"
        },
        \"https://index.docker.io/v1/\":{
          \"auth\":\"$(printf "%s:%s" "${DOCKER_USERNAME}" "${DOCKER_TOKEN}" | base64 | tr -d '\n')\"
        }
      }}" > /kaniko/.docker/config.json
  script:
    - echo "Build image $IMAGE_NAME"
    - source build.env
    - echo "With these environmental variables"
    - cat .env
    - >
      /kaniko/executor
      --force
      --context "$CONTEXT_DIR"
      --dockerfile "$CONTEXT_DIR/Dockerfile"
      --cache=true
      --destination "$IMAGE_NAME-unverified"
      --build-arg EXTERNAL_REG="$EXTERNAL_REG"
      --build-arg INTERNAL_REG="$INTERNAL_REG"
      --build-arg PYTHON_IMG_TAG="$PYTHON_IMG_TAG"
      --build-arg APP_VERSION="$APP_VERSION"
      --build-arg NGINX_IMG_TAG="$NGINX_IMG_TAG"

app-build:
  needs:
    - set-vars
  extends:
    - .triggers
    - .build
  variables:
    IMAGE_NAME: $APP_IMAGE
    CONTEXT_DIR: "$CI_PROJECT_DIR"

proxy-build:
  needs:
    - set-vars
  extends:
    - .triggers
    - .build
  variables:
    IMAGE_NAME: $PROXY_IMAGE
    CONTEXT_DIR: "$CI_PROJECT_DIR/nginx"

.scan:
  stage: scan
  image:
    name: docker.io/aquasec/trivy:0.23.0
    entrypoint: [""]
  variables:
    GIT_STRATEGY: none
  script:
    - echo "Going to scan image $IMAGE_NAME-unverified"
    - trivy --version
    - time trivy image --clear-cache
    - time trivy --cache-dir .trivycache/ image --download-db-only --no-progress
    # Create report artifact
    - >
      time trivy --cache-dir .trivycache/ image --exit-code 0 --ignore-unfixed
      --no-progress --format template --template "@/contrib/gitlab.tpl"
      --output "$CI_PROJECT_DIR/$SHORT_NAME-imgscan.json"
      "${IMAGE_NAME}-unverified"
    # Print full report
    - >
      time trivy --cache-dir .trivycache/ image --exit-code 0 --ignore-unfixed
      --no-progress "${IMAGE_NAME}"-unverified
    # Fail on critical vulnerabilities
    - >
      time trivy --cache-dir .trivycache/ image --exit-code 1 --ignore-unfixed
      --severity CRITICAL --no-progress "${IMAGE_NAME}"-unverified
  cache:
    key: trivy-cache
    paths:
      - .trivycache/
    policy: pull-push
  artifacts:
    when: always
    reports:
      container_scanning: $SHORT_NAME-imgscan.json

app-scan:
  needs:
    - app-build
  extends:
    - .triggers
    - .scan
  variables:
    IMAGE_NAME: $APP_IMAGE
    SHORT_NAME: "app"

proxy-scan:
  needs:
    - proxy-build
  extends:
    - .triggers
    - .scan
  variables:
    IMAGE_NAME: $PROXY_IMAGE
    SHORT_NAME: "proxy"

.retag:
  stage: package
  image: docker.io/regclient/regctl:v0.3-alpine
  variables:
    GIT_STRATEGY: none
  before_script:
    - export REG_HOST=${INTERNAL_REG%/*}
    - >
      echo "{\"hosts\":{\"${REG_HOST}\":{\"tls\":\"enabled\",\"hostname\":
      \"${REG_HOST}\",\"user\":\"${IMAGE_REGISTRY_USER}\",\"pass\":
      \"${IMAGE_REGISTRY_PASS}\"}}}" >> /home/appuser/.regctl/config.json
  script:
    - >
      regctl --verbosity debug image copy
      "$IMAGE_NAME-unverified" "$IMAGE_NAME"
    - regctl --verbosity debug tag delete "$IMAGE_NAME-unverified"

app-retag:
  needs:
    - app-scan
  extends:
    - .triggers
    - .retag
  variables:
    IMAGE_NAME: $APP_IMAGE

proxy-retag:
  needs:
    - proxy-scan
  extends:
    - .triggers
    - .retag
  variables:
    IMAGE_NAME: $PROXY_IMAGE

remote-docker:
  stage: deploy
  environment: $CI_COMMIT_REF_NAME
  image: docker.io/docker:24.0
  needs:
    - app-retag
    - proxy-retag
  extends:
    - .triggers
  variables:
    DOCKER_HOST: "ssh://$DEPLOY_SSH_USER@$DEPLOY_HOSTNAME"
  before_script:
    - echo "*** The app image is '$APP_IMAGE'"
    - echo "*** The app version is '$APP_VERSION'"
    - echo "*** The DataCite API URL is '$DATACITE_API_URL'"
    - echo "*** DATACITE_DATA_URL_PREFIX=$DATACITE_DATA_URL_PREFIX"
    - echo "*** DOI_PREFIX=$DOI_PREFIX"
    - echo "*** DOI_SUFFIX_TAG=$DOI_SUFFIX_TAG"
    - echo "*** Going to docker compose remote with file 'docker-compose.$CI_COMMIT_REF_NAME.yml'"
    - echo "Adding SSH Key"
    - mkdir -p ~/.ssh
    - echo "$DEPLOY_SSH_KEY" >> ~/.ssh/gitlab
    - chmod 400 ~/.ssh/gitlab
    - echo 'IdentityFile ~/.ssh/gitlab' >> ~/.ssh/config
    - ssh-keyscan -H $DEPLOY_HOSTNAME >> ~/.ssh/known_hosts
  script:
    - USER_DIR=$(echo "/home/$DEPLOY_SSH_USER")
    - echo "Defined USER_DIR ${USER_DIR}"
    - HOME=$USER_DIR  
    - echo "going to docker login with user ${DOCKER_USERNAME}"
    - echo "${DOCKER_TOKEN}" | docker login --username "${DOCKER_USERNAME}" --password-stdin
    # use docker compose create to recreate the container and force pulling the latest image
    # to avoid using the local cache
    - |
      docker compose --project-name="$APP_NAME" \
        --file "docker-compose.$CI_COMMIT_REF_NAME.yml" \
        create --force-recreate --pull="always"
    # use docker compose up to start the service on the remote machine
    - |
      docker compose --project-name="$APP_NAME" \
        --file "docker-compose.$CI_COMMIT_REF_NAME.yml" \
        up --detach

# Job for manual deploying of a docker-compose file, to use it's
# docker images, make sure before you run it that the images referenced
# in the docker-compose.$CI_COMMIT_REF_NAME.yml exist!
manual-remote-docker:
  stage: manual-deploy
  environment: $CI_COMMIT_REF_NAME
  image: docker.io/docker:24.0
  rules:
    - if: '$CI_PIPELINE_SOURCE == "pipeline"'
      when: always
    - when: manual
  needs:
    - set-vars
  variables:
    DOCKER_HOST: "ssh://$DEPLOY_SSH_USER@$DEPLOY_HOSTNAME"
  before_script:
    - echo "***The app image is   $APP_IMAGE"
    - echo "***The app version is  $APP_VERSION"
    - echo "Going to docker compose remote with file docker-compose.$CI_COMMIT_REF_NAME.yml"
    - echo "Adding SSH Key"
    - mkdir -p ~/.ssh
    - echo "$DEPLOY_SSH_KEY" >> ~/.ssh/gitlab
    - chmod 400 ~/.ssh/gitlab
    - echo 'IdentityFile ~/.ssh/gitlab' >> ~/.ssh/config
    - ssh-keyscan -H $DEPLOY_HOSTNAME >> ~/.ssh/known_hosts
  script:
    - USER_DIR=$(echo "/home/$DEPLOY_SSH_USER")
    - echo "Defined USER_DIR ${USER_DIR}"
    - HOME=$USER_DIR
    - echo "going to docker login with user ${DOCKER_USERNAME}"
    - echo "${DOCKER_TOKEN}" | docker login --username "${DOCKER_USERNAME}" --password-stdin
    - > 
      if ! docker network inspect envidat >/dev/null 2>&1; then 
        docker network create envidat
      fi
    - echo "Going to remotely start the docker-compose.${CI_COMMIT_REF_NAME}.yml on ${DEPLOY_SSH_USER}@${DEPLOY_HOSTNAME}"
    # use docker compose create to recreate the container and force pulling the latest image
    # to avoid using the local cache
    - |
      docker compose --project-name="$APP_NAME" \
        --file "docker-compose.$CI_COMMIT_REF_NAME.yml" \
        create --force-recreate --pull="always"
    # use docker compose up to start the service on the remote machine
    - |
      docker compose --project-name="$APP_NAME" \
        --file "docker-compose.$CI_COMMIT_REF_NAME.yml" \
        up --detach
